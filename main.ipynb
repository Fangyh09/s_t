{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing ELMo.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loadding elmo\n",
      "finish loading\n",
      "ok??????????????????????\n",
      "ok!!!!!!!!!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "from allennlp.commands.elmo import ElmoEmbedder\n",
    "\n",
    "options_file = \"Elmo/data/elmo_2x4096_512_2048cnn_2xhighway_options.json\"\n",
    "weight_file = \"Elmo/data/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\"\n",
    "\n",
    "print(\"loadding elmo\")\n",
    "elmo = ElmoEmbedder(options_file, weight_file, cuda_device=0)\n",
    "print(\"finish loading\")\n",
    "\n",
    "print(\"ok??????????????????????\")\n",
    "elmo_embedding = elmo.embed_sentence([\"I\", \"Love\", \"You\"])\n",
    "print(\"ok!!!!!!!!!!!!!!!!!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pdb; pdb.set_trace()\n",
    "# from config import Config\n",
    "# from model.data_utils import CoNLLDataset\n",
    "# from model.ner_model import NERModel\n",
    "# import ray\n",
    "# import ray.tune as tune\n",
    "\n",
    "# config = Config()\n",
    "\n",
    "# # build model\n",
    "# model = NERModel(config)\n",
    "# model.build()\n",
    "# # model.restore_session(\"results/crf/model.weights/\") # optional, restore weights\n",
    "# #model.reinitialize_weights(\"proj\")\n",
    "\n",
    "\n",
    "# # create datasets\n",
    "\n",
    "\n",
    "# dev   = CoNLLDataset(config.filename_dev, elmo, config.processing_word,\n",
    "#                  config.processing_tag, config.max_iter)\n",
    "# train = CoNLLDataset(config.filename_train, elmo, config.processing_word,\n",
    "#                  config.processing_tag, config.max_iter)\n",
    "\n",
    "# # train model\n",
    "# model.train(train, dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatches(data, minibatch_size, elmo):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        data: generator of (sentence, tags) tuples\n",
    "        minibatch_size: (int)\n",
    "\n",
    "    Yields:\n",
    "        list of tuples\n",
    "\n",
    "    \"\"\"\n",
    "    # import alog\n",
    "    # alog.info(\"!!! I am here\")\n",
    "    x_batch, y_batch = [], []\n",
    "    z_batch = []\n",
    "    for (x, y, z) in data:\n",
    "        if len(x_batch) == minibatch_size:\n",
    "            activations, mask = elmo.batch_to_embeddings(z_batch)\n",
    "            activations = np.transpose(activations, (0, 2, 1, 3))\n",
    "            activations = activations.reshape(activations.shape[0],\n",
    "                                              activations.shape[1],\n",
    "                                              -1)\n",
    "            z_batch = activations.cpu().numpy()\n",
    "            # print(\"shape\", z_batch.shape)\n",
    "            yield x_batch, y_batch, z_batch.tolist()\n",
    "\n",
    "            x_batch, y_batch = [], []\n",
    "            z_batch = []\n",
    "\n",
    "        if type(x[0]) == tuple:\n",
    "            x = zip(*x)\n",
    "\n",
    "        x_batch += [x]\n",
    "        y_batch += [y]\n",
    "        z_batch += [z]\n",
    "\n",
    "\n",
    "    # z_batch = np.array(z_batch)\n",
    "    # alog.info(\"!!! I am out\")\n",
    "\n",
    "    if len(x_batch) != 0:\n",
    "        activations, mask = elmo.batch_to_embeddings(z_batch)\n",
    "        activations = np.transpose(activations, (0, 2, 1, 3))\n",
    "        activations = activations.reshape(activations.shape[0],\n",
    "                                          activations.shape[1],\n",
    "                                          -1)\n",
    "        z_batch = activations.cpu().numpy()\n",
    "        # print(\"shape\", z_batch.shape)\n",
    "        yield x_batch, y_batch, z_batch.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dev = CoNLLDataset(config.filename_dev,\n",
    "                   config.processing_word,\n",
    "                   config.processing_tag,\n",
    "                   config.max_iter)\n",
    "train = CoNLLDataset(config.filename_train,\n",
    "                     config.processing_word,\n",
    "                     config.processing_tag,\n",
    "                     config.max_iter)\n",
    "test = CoNLLDataset(config.filename_test,\n",
    "                     config.processing_word,\n",
    "                     config.processing_tag,\n",
    "                     config.max_iter, test=True)\n",
    "batch_size = 10\n",
    "out_file = \"./elmo_test.embedding\"\n",
    "\n",
    "elmo_embedding_all = []\n",
    "for i, (words, labels, elmo_embedding) in enumerate(minibatches(test, batch_size, elmo)):\n",
    "    elmo_embedding_all.append(elmo_embedding)\n",
    "np.savez(out_file, all_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [00:00, 302.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23, 3072)\n",
      "(2, 3072)\n",
      "(10, 3072)\n",
      "(10, 3072)\n",
      "(2, 3072)\n",
      "(15, 3072)\n",
      "(6, 3072)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "152it [00:00, 347.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3072)\n",
      "(3, 3072)\n",
      "(4, 3072)\n",
      "(8, 3072)\n",
      "(2, 3072)\n",
      "(3, 3072)\n",
      "(6, 3072)\n",
      "(3, 3072)\n",
      "(2, 3072)\n",
      "(4, 3072)\n",
      "(6, 3072)\n",
      "(7, 3072)\n",
      "(2, 3072)\n",
      "(2, 3072)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "263it [00:00, 382.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 3072)\n",
      "(18, 3072)\n",
      "(2, 3072)\n",
      "(12, 3072)\n",
      "(5, 3072)\n",
      "(39, 3072)\n",
      "(2, 3072)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "300it [00:00, 370.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3072)\n",
      "(4, 3072)\n",
      "(9, 3072)\n",
      "(9, 3072)\n",
      "(2, 3072)\n",
      "(21, 3072)\n",
      "(3, 3072)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "390it [00:01, 369.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 3072)\n",
      "(2, 3072)\n",
      "(18, 3072)\n",
      "(5, 3072)\n",
      "(11, 3072)\n",
      "(5, 3072)\n",
      "(3, 3072)\n",
      "(8, 3072)\n",
      "(6, 3072)\n",
      "(3, 3072)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "496it [00:01, 383.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 3072)\n",
      "(4, 3072)\n",
      "(2, 3072)\n",
      "(3, 3072)\n",
      "(21, 3072)\n",
      "(21, 3072)\n",
      "(13, 3072)\n",
      "(19, 3072)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "609it [00:01, 393.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 3072)\n",
      "(6, 3072)\n",
      "(13, 3072)\n",
      "(10, 3072)\n",
      "(24, 3072)\n",
      "(2, 3072)\n",
      "(2, 3072)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "705it [00:01, 394.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 3072)\n",
      "(2, 3072)\n",
      "(24, 3072)\n",
      "(13, 3072)\n",
      "(19, 3072)\n",
      "(6, 3072)\n",
      "(2, 3072)\n",
      "(3, 3072)\n",
      "(3, 3072)\n",
      "(3, 3072)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "762it [00:01, 399.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33, 3072)\n",
      "(14, 3072)\n",
      "(2, 3072)\n",
      "(2, 3072)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a3a12a7dbf51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0;31m# use_elmo = True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0;31m# if use_elmo:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                 \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melmo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                 \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/pyenv-allennlp/lib/python3.6/site-packages/allennlp/commands/elmo.py\u001b[0m in \u001b[0;36membed_sentence\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \"\"\"\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0membed_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/pyenv-allennlp/lib/python3.6/site-packages/allennlp/commands/elmo.py\u001b[0m in \u001b[0;36membed_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0melmo_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mempty_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_to_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/pyenv-allennlp/lib/python3.6/site-packages/allennlp/commands/elmo.py\u001b[0m in \u001b[0;36mbatch_to_embeddings\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mcharacter_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcharacter_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mbilm_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melmo_bilm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcharacter_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0mlayer_activations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbilm_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'activations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mmask_with_bos_eos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbilm_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/pyenv-allennlp/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/pyenv-allennlp/lib/python3.6/site-packages/allennlp/modules/elmo.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, word_inputs)\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_embedding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0mtype_representation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_embedding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_embedding'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0mlstm_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elmo_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_representation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;31m# Prepare the output.  The first layer is duplicated.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/pyenv-allennlp/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/pyenv-allennlp/lib/python3.6/site-packages/allennlp/modules/elmo_lstm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_sequence_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mstacked_sequence_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestoration_indices\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_and_run_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lstm_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturned_timesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstacked_sequence_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/pyenv-allennlp/lib/python3.6/site-packages/allennlp/modules/encoder_base.py\u001b[0m in \u001b[0;36msort_and_run_forward\u001b[0;34m(self, module, inputs, mask, hidden_state)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# Actually call the module on the sorted PackedSequence.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mmodule_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_sequence_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestoration_indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/pyenv-allennlp/lib/python3.6/site-packages/allennlp/modules/elmo_lstm.py\u001b[0m in \u001b[0;36m_lstm_forward\u001b[0;34m(self, inputs, initial_state)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             sequence_outputs.append(torch.cat([forward_output_sequence,\n\u001b[0;32m--> 227\u001b[0;31m                                                backward_output_sequence], -1))\n\u001b[0m\u001b[1;32m    228\u001b[0m             \u001b[0;31m# Append the state tuples in a list, so that we can return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;31m# the final states for all the layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import pdb; pdb.set_trace()\n",
    "import numpy as np\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "out_file = \"./elmo_train.embedding\"\n",
    "all_embedding = []\n",
    "filename = \"/SSD1/yinghong/tmp/s_t_elmo/data/train.eval.ebieo\"\n",
    "with open(filename) as f:\n",
    "    words, tags = [], []\n",
    "    orig_words = []\n",
    "    # elmo_embedding = []\n",
    "    for line in tqdm(f):\n",
    "        line = line.strip()\n",
    "        if (len(line) == 0 or line.startswith(\"-DOCSTART-\")):\n",
    "            if len(words) != 0:\n",
    "                # niter += 1\n",
    "                # if self.max_iter is not None and niter > self.max_iter:\n",
    "                #     break\n",
    "                # todo remote it\n",
    "                # use_elmo = True\n",
    "                # if use_elmo:\n",
    "                embedding = elmo.embed_sentence(orig_words)\n",
    "                embedding = np.transpose(embedding, (1, 0, 2))\n",
    "                embedding = embedding.reshape(embedding.shape[0], -1)\n",
    "                embedding = np.array(embedding)\n",
    "                print(embedding.shape)\n",
    "                all_embedding.append(embedding)\n",
    "                # yield words, tags, self.elmo.embed_sentence(orig_words)\n",
    "                words, tags = [], []\n",
    "                orig_words = []\n",
    "        else:\n",
    "            ls = line.split(' ')\n",
    "            word, tag = ls[0], ls[-1]\n",
    "           \n",
    "            words += [word]\n",
    "            tags += [tag]\n",
    "            orig_words += [word]\n",
    "    all_embedding = np.array(all_embedding)\n",
    "    np.savez(out_file, all_embedding)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yinghong/.pyenv/versions/pyenv-allennlp/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "Initializing tf session\n",
      "Epoch 1 out of 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (10, 32, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "   1/1143 [..............................] - ETA: 839s - train loss: 23.6247shape (10, 8, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "   2/1143 [..............................] - ETA: 514s - train loss: 15.4503shape (10, 39, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "   3/1143 [..............................] - ETA: 469s - train loss: 22.2343shape (10, 21, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "   4/1143 [..............................] - ETA: 430s - train loss: 20.7916shape (10, 25, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "   5/1143 [..............................] - ETA: 401s - train loss: 18.5422shape (10, 24, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "   6/1143 [..............................] - ETA: 383s - train loss: 17.6550shape (10, 24, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "   7/1143 [..............................] - ETA: 366s - train loss: 16.9723shape (10, 33, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "   8/1143 [..............................] - ETA: 363s - train loss: 15.9675shape (10, 20, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "   9/1143 [..............................] - ETA: 355s - train loss: 15.3297shape (10, 20, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  10/1143 [..............................] - ETA: 345s - train loss: 15.1789shape (10, 14, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  11/1143 [..............................] - ETA: 330s - train loss: 14.4360shape (10, 21, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  12/1143 [..............................] - ETA: 324s - train loss: 14.0378shape (10, 19, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  13/1143 [..............................] - ETA: 316s - train loss: 13.5902shape (10, 29, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  14/1143 [..............................] - ETA: 317s - train loss: 13.1675shape (10, 44, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  15/1143 [..............................] - ETA: 327s - train loss: 13.2004shape (10, 10, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  16/1143 [..............................] - ETA: 316s - train loss: 12.6027shape (10, 18, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  17/1143 [..............................] - ETA: 311s - train loss: 12.0631shape (10, 31, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  18/1143 [..............................] - ETA: 312s - train loss: 12.4405shape (10, 19, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  19/1143 [..............................] - ETA: 306s - train loss: 12.4079shape (10, 25, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  20/1143 [..............................] - ETA: 305s - train loss: 12.2972shape (10, 8, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  21/1143 [..............................] - ETA: 296s - train loss: 11.9646shape (10, 7, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  22/1143 [..............................] - ETA: 289s - train loss: 11.5250shape (10, 28, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  23/1143 [..............................] - ETA: 289s - train loss: 11.3570shape (10, 35, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  24/1143 [..............................] - ETA: 292s - train loss: 11.4258shape (10, 39, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  25/1143 [..............................] - ETA: 299s - train loss: 11.8799shape (10, 41, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  26/1143 [..............................] - ETA: 303s - train loss: 11.7875shape (10, 34, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  27/1143 [..............................] - ETA: 305s - train loss: 12.0129shape (10, 35, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  28/1143 [..............................] - ETA: 306s - train loss: 11.9137shape (10, 18, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  29/1143 [..............................] - ETA: 304s - train loss: 11.6661shape (10, 16, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  30/1143 [..............................] - ETA: 301s - train loss: 11.3940shape (10, 74, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  31/1143 [..............................] - ETA: 314s - train loss: 11.7983shape (10, 22, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  32/1143 [..............................] - ETA: 312s - train loss: 11.5936shape (10, 29, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  33/1143 [..............................] - ETA: 311s - train loss: 11.4338shape (10, 54, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  34/1143 [..............................] - ETA: 317s - train loss: 11.4667shape (10, 17, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  35/1143 [..............................] - ETA: 315s - train loss: 11.3096shape (10, 9, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  36/1143 [..............................] - ETA: 310s - train loss: 11.0964shape (10, 14, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  37/1143 [..............................] - ETA: 308s - train loss: 10.9304shape (10, 18, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  38/1143 [..............................] - ETA: 305s - train loss: 10.7198shape (10, 14, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  39/1143 [>.............................] - ETA: 302s - train loss: 10.5677shape (10, 27, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  40/1143 [>.............................] - ETA: 301s - train loss: 10.5995shape (10, 85, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  41/1143 [>.............................] - ETA: 311s - train loss: 10.7875shape (10, 13, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  42/1143 [>.............................] - ETA: 309s - train loss: 10.6269shape (10, 24, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  43/1143 [>.............................] - ETA: 309s - train loss: 10.5533shape (10, 22, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  44/1143 [>.............................] - ETA: 307s - train loss: 10.4577shape (10, 23, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  45/1143 [>.............................] - ETA: 306s - train loss: 10.3349shape (10, 36, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  46/1143 [>.............................] - ETA: 307s - train loss: 10.5159shape (10, 22, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  47/1143 [>.............................] - ETA: 306s - train loss: 10.4082shape (10, 16, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  48/1143 [>.............................] - ETA: 303s - train loss: 10.2501shape (10, 24, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  49/1143 [>.............................] - ETA: 302s - train loss: 10.0875shape (10, 34, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  50/1143 [>.............................] - ETA: 302s - train loss: 10.0651shape (10, 11, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  51/1143 [>.............................] - ETA: 300s - train loss: 9.9313 shape (10, 26, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  52/1143 [>.............................] - ETA: 300s - train loss: 9.8185shape (10, 57, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  53/1143 [>.............................] - ETA: 305s - train loss: 9.7910shape (10, 25, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  54/1143 [>.............................] - ETA: 305s - train loss: 9.7298shape (10, 26, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  55/1143 [>.............................] - ETA: 303s - train loss: 9.6926shape (10, 24, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  56/1143 [>.............................] - ETA: 302s - train loss: 9.6862shape (10, 33, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  57/1143 [>.............................] - ETA: 303s - train loss: 9.6999shape (10, 11, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  58/1143 [>.............................] - ETA: 300s - train loss: 9.5687shape (10, 15, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  59/1143 [>.............................] - ETA: 298s - train loss: 9.4822shape (10, 33, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  60/1143 [>.............................] - ETA: 298s - train loss: 9.5091shape (10, 17, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  61/1143 [>.............................] - ETA: 296s - train loss: 9.4369shape (10, 17, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  62/1143 [>.............................] - ETA: 294s - train loss: 9.3671shape (10, 22, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  63/1143 [>.............................] - ETA: 292s - train loss: 9.3179shape (10, 25, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  64/1143 [>.............................] - ETA: 292s - train loss: 9.2799shape (10, 24, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  65/1143 [>.............................] - ETA: 291s - train loss: 9.1700shape (10, 20, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  66/1143 [>.............................] - ETA: 290s - train loss: 9.1491shape (10, 39, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  67/1143 [>.............................] - ETA: 291s - train loss: 9.1252shape (10, 23, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  68/1143 [>.............................] - ETA: 291s - train loss: 9.1204shape (10, 16, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  69/1143 [>.............................] - ETA: 289s - train loss: 9.0558shape (10, 26, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  70/1143 [>.............................] - ETA: 289s - train loss: 9.0001shape (10, 21, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  71/1143 [>.............................] - ETA: 288s - train loss: 8.9513shape (10, 21, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  72/1143 [>.............................] - ETA: 287s - train loss: 8.9188shape (10, 20, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  73/1143 [>.............................] - ETA: 285s - train loss: 8.8419shape (10, 23, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  74/1143 [>.............................] - ETA: 285s - train loss: 8.8553shape (10, 20, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  75/1143 [>.............................] - ETA: 284s - train loss: 8.8160shape (10, 30, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  76/1143 [>.............................] - ETA: 283s - train loss: 8.8352shape (10, 19, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  77/1143 [=>............................] - ETA: 282s - train loss: 8.7897shape (10, 37, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  78/1143 [=>............................] - ETA: 284s - train loss: 8.7326shape (10, 24, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  79/1143 [=>............................] - ETA: 284s - train loss: 8.7562shape (10, 56, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  80/1143 [=>............................] - ETA: 286s - train loss: 8.7518shape (10, 29, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  81/1143 [=>............................] - ETA: 286s - train loss: 8.7148shape (10, 18, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  82/1143 [=>............................] - ETA: 285s - train loss: 8.6804shape (10, 16, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  83/1143 [=>............................] - ETA: 283s - train loss: 8.6161shape (10, 19, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  84/1143 [=>............................] - ETA: 282s - train loss: 8.5473shape (10, 21, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  85/1143 [=>............................] - ETA: 281s - train loss: 8.5225shape (10, 36, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  86/1143 [=>............................] - ETA: 282s - train loss: 8.5580shape (10, 18, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  87/1143 [=>............................] - ETA: 281s - train loss: 8.5241shape (10, 26, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  88/1143 [=>............................] - ETA: 281s - train loss: 8.5340shape (10, 37, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  89/1143 [=>............................] - ETA: 281s - train loss: 8.4760shape (10, 28, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  90/1143 [=>............................] - ETA: 281s - train loss: 8.4367shape (10, 18, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  91/1143 [=>............................] - ETA: 280s - train loss: 8.3905shape (10, 24, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  92/1143 [=>............................] - ETA: 279s - train loss: 8.3761shape (10, 36, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  93/1143 [=>............................] - ETA: 280s - train loss: 8.3809shape (10, 27, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  94/1143 [=>............................] - ETA: 280s - train loss: 8.3579shape (10, 47, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  95/1143 [=>............................] - ETA: 281s - train loss: 8.4165shape (10, 32, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  96/1143 [=>............................] - ETA: 281s - train loss: 8.3768shape (10, 15, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  97/1143 [=>............................] - ETA: 280s - train loss: 8.3357shape (10, 23, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  98/1143 [=>............................] - ETA: 279s - train loss: 8.3210shape (10, 26, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      "  99/1143 [=>............................] - ETA: 278s - train loss: 8.2996shape (10, 8, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 100/1143 [=>............................] - ETA: 277s - train loss: 8.2263shape (10, 26, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 101/1143 [=>............................] - ETA: 276s - train loss: 8.2185shape (10, 30, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 102/1143 [=>............................] - ETA: 276s - train loss: 8.1727shape (10, 28, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 103/1143 [=>............................] - ETA: 275s - train loss: 8.1795shape (10, 21, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 104/1143 [=>............................] - ETA: 274s - train loss: 8.1493shape (10, 11, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 105/1143 [=>............................] - ETA: 273s - train loss: 8.0894shape (10, 14, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 106/1143 [=>............................] - ETA: 272s - train loss: 8.0874shape (10, 34, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 107/1143 [=>............................] - ETA: 271s - train loss: 8.0738shape (10, 28, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 108/1143 [=>............................] - ETA: 271s - train loss: 8.0341shape (10, 30, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 109/1143 [=>............................] - ETA: 271s - train loss: 8.0478shape (10, 30, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 110/1143 [=>............................] - ETA: 271s - train loss: 8.0392shape (10, 38, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 111/1143 [=>............................] - ETA: 271s - train loss: 8.0142shape (10, 15, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 112/1143 [=>............................] - ETA: 271s - train loss: 7.9788shape (10, 22, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 113/1143 [=>............................] - ETA: 270s - train loss: 7.9780shape (10, 111, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 114/1143 [=>............................] - ETA: 275s - train loss: 7.9761shape (10, 40, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 115/1143 [==>...........................] - ETA: 276s - train loss: 7.9679shape (10, 30, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 116/1143 [==>...........................] - ETA: 276s - train loss: 7.9376shape (10, 53, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 117/1143 [==>...........................] - ETA: 277s - train loss: 7.9440shape (10, 16, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 118/1143 [==>...........................] - ETA: 277s - train loss: 7.8960shape (10, 25, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 119/1143 [==>...........................] - ETA: 276s - train loss: 7.8612shape (10, 22, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 120/1143 [==>...........................] - ETA: 275s - train loss: 7.8445shape (10, 41, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 121/1143 [==>...........................] - ETA: 275s - train loss: 7.8560shape (10, 27, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 122/1143 [==>...........................] - ETA: 275s - train loss: 7.8387shape (10, 30, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 123/1143 [==>...........................] - ETA: 275s - train loss: 7.8492shape (10, 16, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 124/1143 [==>...........................] - ETA: 274s - train loss: 7.7996shape (10, 28, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 125/1143 [==>...........................] - ETA: 274s - train loss: 7.7635shape (10, 22, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 126/1143 [==>...........................] - ETA: 273s - train loss: 7.7400shape (10, 14, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 127/1143 [==>...........................] - ETA: 273s - train loss: 7.7157shape (10, 25, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 128/1143 [==>...........................] - ETA: 272s - train loss: 7.6812shape (10, 17, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 129/1143 [==>...........................] - ETA: 271s - train loss: 7.6481shape (10, 16, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 130/1143 [==>...........................] - ETA: 270s - train loss: 7.6178shape (10, 35, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 131/1143 [==>...........................] - ETA: 271s - train loss: 7.6115shape (10, 13, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 132/1143 [==>...........................] - ETA: 270s - train loss: 7.5764shape (10, 21, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 133/1143 [==>...........................] - ETA: 269s - train loss: 7.5648shape (10, 25, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 134/1143 [==>...........................] - ETA: 269s - train loss: 7.5202shape (10, 19, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 135/1143 [==>...........................] - ETA: 268s - train loss: 7.4962shape (10, 29, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 136/1143 [==>...........................] - ETA: 268s - train loss: 7.5044shape (10, 32, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 137/1143 [==>...........................] - ETA: 268s - train loss: 7.5012shape (10, 26, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 138/1143 [==>...........................] - ETA: 268s - train loss: 7.5058shape (10, 51, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 139/1143 [==>...........................] - ETA: 269s - train loss: 7.5488shape (10, 10, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 140/1143 [==>...........................] - ETA: 268s - train loss: 7.5347shape (10, 13, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 141/1143 [==>...........................] - ETA: 267s - train loss: 7.5217shape (10, 20, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 142/1143 [==>...........................] - ETA: 267s - train loss: 7.5033shape (10, 11, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 143/1143 [==>...........................] - ETA: 266s - train loss: 7.4711shape (10, 36, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 144/1143 [==>...........................] - ETA: 266s - train loss: 7.4372shape (10, 32, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 145/1143 [==>...........................] - ETA: 266s - train loss: 7.4441shape (10, 31, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 146/1143 [==>...........................] - ETA: 266s - train loss: 7.4428shape (10, 26, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 147/1143 [==>...........................] - ETA: 266s - train loss: 7.4370shape (10, 17, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 148/1143 [==>...........................] - ETA: 265s - train loss: 7.4125shape (10, 27, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 149/1143 [==>...........................] - ETA: 264s - train loss: 7.4082shape (10, 32, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 150/1143 [==>...........................] - ETA: 264s - train loss: 7.4202shape (10, 29, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 151/1143 [==>...........................] - ETA: 264s - train loss: 7.4144shape (10, 13, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 152/1143 [==>...........................] - ETA: 263s - train loss: 7.3778shape (10, 77, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 153/1143 [===>..........................] - ETA: 265s - train loss: 7.3869shape (10, 22, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 154/1143 [===>..........................] - ETA: 265s - train loss: 7.3695shape (10, 14, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 155/1143 [===>..........................] - ETA: 264s - train loss: 7.3303shape (10, 34, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 156/1143 [===>..........................] - ETA: 264s - train loss: 7.3114shape (10, 50, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 157/1143 [===>..........................] - ETA: 265s - train loss: 7.2851shape (10, 36, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 158/1143 [===>..........................] - ETA: 265s - train loss: 7.2734shape (10, 36, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 159/1143 [===>..........................] - ETA: 265s - train loss: 7.3181shape (10, 27, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 160/1143 [===>..........................] - ETA: 265s - train loss: 7.2848shape (10, 23, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 161/1143 [===>..........................] - ETA: 264s - train loss: 7.2615shape (10, 20, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 162/1143 [===>..........................] - ETA: 264s - train loss: 7.2576shape (10, 17, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 163/1143 [===>..........................] - ETA: 263s - train loss: 7.2253shape (10, 24, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 164/1143 [===>..........................] - ETA: 263s - train loss: 7.2172shape (10, 18, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 165/1143 [===>..........................] - ETA: 262s - train loss: 7.1838shape (10, 13, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 166/1143 [===>..........................] - ETA: 261s - train loss: 7.1686shape (10, 22, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 167/1143 [===>..........................] - ETA: 261s - train loss: 7.1561shape (10, 36, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 168/1143 [===>..........................] - ETA: 261s - train loss: 7.1702shape (10, 47, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 169/1143 [===>..........................] - ETA: 261s - train loss: 7.1716shape (10, 23, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 170/1143 [===>..........................] - ETA: 261s - train loss: 7.1581shape (10, 27, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 171/1143 [===>..........................] - ETA: 260s - train loss: 7.1599shape (10, 11, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 172/1143 [===>..........................] - ETA: 260s - train loss: 7.1288shape (10, 29, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 173/1143 [===>..........................] - ETA: 259s - train loss: 7.1156shape (10, 21, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 174/1143 [===>..........................] - ETA: 259s - train loss: 7.0955shape (10, 28, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 175/1143 [===>..........................] - ETA: 259s - train loss: 7.0863shape (10, 25, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 176/1143 [===>..........................] - ETA: 258s - train loss: 7.0650shape (10, 22, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 177/1143 [===>..........................] - ETA: 258s - train loss: 7.0538shape (10, 16, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 178/1143 [===>..........................] - ETA: 257s - train loss: 7.0202shape (10, 23, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 179/1143 [===>..........................] - ETA: 257s - train loss: 6.9981shape (10, 42, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 180/1143 [===>..........................] - ETA: 258s - train loss: 6.9852shape (10, 37, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 181/1143 [===>..........................] - ETA: 258s - train loss: 7.0051shape (10, 19, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 182/1143 [===>..........................] - ETA: 257s - train loss: 6.9880shape (10, 14, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 183/1143 [===>..........................] - ETA: 257s - train loss: 6.9609shape (10, 26, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 184/1143 [===>..........................] - ETA: 256s - train loss: 6.9427shape (10, 68, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 185/1143 [===>..........................] - ETA: 257s - train loss: 6.9303shape (10, 18, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 186/1143 [===>..........................] - ETA: 257s - train loss: 6.9033shape (10, 23, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 187/1143 [===>..........................] - ETA: 257s - train loss: 6.8875shape (10, 12, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 188/1143 [===>..........................] - ETA: 256s - train loss: 6.8678shape (10, 23, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 189/1143 [===>..........................] - ETA: 255s - train loss: 6.8439shape (10, 19, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 190/1143 [===>..........................] - ETA: 255s - train loss: 6.8291shape (10, 32, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 191/1143 [====>.........................] - ETA: 255s - train loss: 6.8246shape (10, 14, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 192/1143 [====>.........................] - ETA: 254s - train loss: 6.8014shape (10, 24, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 193/1143 [====>.........................] - ETA: 253s - train loss: 6.7806shape (10, 30, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 194/1143 [====>.........................] - ETA: 253s - train loss: 6.7714shape (10, 16, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 195/1143 [====>.........................] - ETA: 253s - train loss: 6.7449shape (10, 21, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 196/1143 [====>.........................] - ETA: 252s - train loss: 6.7371shape (10, 32, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 197/1143 [====>.........................] - ETA: 252s - train loss: 6.7257shape (10, 24, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 198/1143 [====>.........................] - ETA: 252s - train loss: 6.7253shape (10, 17, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 199/1143 [====>.........................] - ETA: 251s - train loss: 6.7008shape (10, 23, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 200/1143 [====>.........................] - ETA: 251s - train loss: 6.7006shape (10, 33, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 201/1143 [====>.........................] - ETA: 251s - train loss: 6.7053shape (10, 45, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 202/1143 [====>.........................] - ETA: 251s - train loss: 6.7060shape (10, 25, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 203/1143 [====>.........................] - ETA: 251s - train loss: 6.6877shape (10, 18, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 204/1143 [====>.........................] - ETA: 251s - train loss: 6.6611shape (10, 32, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 205/1143 [====>.........................] - ETA: 250s - train loss: 6.6566shape (10, 16, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 206/1143 [====>.........................] - ETA: 250s - train loss: 6.6316shape (10, 41, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 207/1143 [====>.........................] - ETA: 250s - train loss: 6.6509shape (10, 34, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 208/1143 [====>.........................] - ETA: 250s - train loss: 6.6437shape (10, 25, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 209/1143 [====>.........................] - ETA: 250s - train loss: 6.6462shape (10, 19, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 210/1143 [====>.........................] - ETA: 250s - train loss: 6.6397shape (10, 38, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 211/1143 [====>.........................] - ETA: 250s - train loss: 6.6329shape (10, 36, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 212/1143 [====>.........................] - ETA: 250s - train loss: 6.6261shape (10, 25, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 213/1143 [====>.........................] - ETA: 250s - train loss: 6.6188shape (10, 33, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 214/1143 [====>.........................] - ETA: 249s - train loss: 6.6136shape (10, 42, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 215/1143 [====>.........................] - ETA: 250s - train loss: 6.6016shape (10, 16, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 216/1143 [====>.........................] - ETA: 249s - train loss: 6.5818shape (10, 25, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 217/1143 [====>.........................] - ETA: 249s - train loss: 6.5697shape (10, 21, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 218/1143 [====>.........................] - ETA: 248s - train loss: 6.5513shape (10, 12, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 219/1143 [====>.........................] - ETA: 248s - train loss: 6.5286shape (10, 22, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 220/1143 [====>.........................] - ETA: 247s - train loss: 6.5265shape (10, 15, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 221/1143 [====>.........................] - ETA: 246s - train loss: 6.5022shape (10, 40, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 222/1143 [====>.........................] - ETA: 247s - train loss: 6.4906shape (10, 43, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 223/1143 [====>.........................] - ETA: 247s - train loss: 6.4854shape (10, 9, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 224/1143 [====>.........................] - ETA: 246s - train loss: 6.4682shape (10, 22, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 225/1143 [====>.........................] - ETA: 246s - train loss: 6.4528shape (10, 24, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 226/1143 [====>.........................] - ETA: 245s - train loss: 6.4288shape (10, 22, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 227/1143 [====>.........................] - ETA: 245s - train loss: 6.4208shape (10, 26, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 228/1143 [====>.........................] - ETA: 244s - train loss: 6.4133shape (10, 22, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 229/1143 [=====>........................] - ETA: 244s - train loss: 6.3996shape (10, 21, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 230/1143 [=====>........................] - ETA: 243s - train loss: 6.3775shape (10, 33, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 231/1143 [=====>........................] - ETA: 243s - train loss: 6.3608shape (10, 29, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 232/1143 [=====>........................] - ETA: 243s - train loss: 6.3391shape (10, 22, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 233/1143 [=====>........................] - ETA: 243s - train loss: 6.3381shape (10, 46, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 234/1143 [=====>........................] - ETA: 243s - train loss: 6.3297shape (10, 38, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 235/1143 [=====>........................] - ETA: 243s - train loss: 6.3194shape (10, 32, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 236/1143 [=====>........................] - ETA: 242s - train loss: 6.3084shape (10, 25, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 237/1143 [=====>........................] - ETA: 242s - train loss: 6.3026shape (10, 25, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 238/1143 [=====>........................] - ETA: 242s - train loss: 6.2915shape (10, 22, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 239/1143 [=====>........................] - ETA: 241s - train loss: 6.2822shape (10, 23, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 240/1143 [=====>........................] - ETA: 241s - train loss: 6.2655shape (10, 16, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 241/1143 [=====>........................] - ETA: 241s - train loss: 6.2428shape (10, 30, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 242/1143 [=====>........................] - ETA: 240s - train loss: 6.2520shape (10, 28, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 243/1143 [=====>........................] - ETA: 240s - train loss: 6.2434shape (10, 32, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 244/1143 [=====>........................] - ETA: 240s - train loss: 6.2476shape (10, 25, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 245/1143 [=====>........................] - ETA: 240s - train loss: 6.2325shape (10, 23, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 246/1143 [=====>........................] - ETA: 239s - train loss: 6.2199shape (10, 8, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 247/1143 [=====>........................] - ETA: 238s - train loss: 6.1979shape (10, 35, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 248/1143 [=====>........................] - ETA: 238s - train loss: 6.1939shape (10, 24, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 249/1143 [=====>........................] - ETA: 238s - train loss: 6.1759shape (10, 39, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 250/1143 [=====>........................] - ETA: 238s - train loss: 6.1968shape (10, 18, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 251/1143 [=====>........................] - ETA: 238s - train loss: 6.1889shape (10, 18, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 252/1143 [=====>........................] - ETA: 237s - train loss: 6.1775shape (10, 26, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 253/1143 [=====>........................] - ETA: 237s - train loss: 6.1686shape (10, 24, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 254/1143 [=====>........................] - ETA: 236s - train loss: 6.1641shape (10, 22, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 255/1143 [=====>........................] - ETA: 236s - train loss: 6.1530shape (10, 24, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 256/1143 [=====>........................] - ETA: 236s - train loss: 6.1373shape (10, 36, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 257/1143 [=====>........................] - ETA: 236s - train loss: 6.1423shape (10, 31, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 258/1143 [=====>........................] - ETA: 235s - train loss: 6.1329shape (10, 23, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 259/1143 [=====>........................] - ETA: 235s - train loss: 6.1173shape (10, 23, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 260/1143 [=====>........................] - ETA: 235s - train loss: 6.1034shape (10, 49, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 261/1143 [=====>........................] - ETA: 235s - train loss: 6.1010shape (10, 13, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 262/1143 [=====>........................] - ETA: 234s - train loss: 6.0881shape (10, 19, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 263/1143 [=====>........................] - ETA: 234s - train loss: 6.0777shape (10, 39, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 264/1143 [=====>........................] - ETA: 234s - train loss: 6.0690shape (10, 19, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 265/1143 [=====>........................] - ETA: 233s - train loss: 6.0593shape (10, 20, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 266/1143 [=====>........................] - ETA: 233s - train loss: 6.0477shape (10, 17, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 267/1143 [======>.......................] - ETA: 232s - train loss: 6.0374shape (10, 43, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 268/1143 [======>.......................] - ETA: 233s - train loss: 6.0342shape (10, 15, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 269/1143 [======>.......................] - ETA: 232s - train loss: 6.0203shape (10, 56, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 270/1143 [======>.......................] - ETA: 232s - train loss: 6.0318shape (10, 43, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 271/1143 [======>.......................] - ETA: 233s - train loss: 6.0377shape (10, 16, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 272/1143 [======>.......................] - ETA: 232s - train loss: 6.0262shape (10, 26, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 273/1143 [======>.......................] - ETA: 232s - train loss: 6.0209shape (10, 25, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 274/1143 [======>.......................] - ETA: 232s - train loss: 6.0100shape (10, 40, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 275/1143 [======>.......................] - ETA: 232s - train loss: 6.0101shape (10, 19, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 276/1143 [======>.......................] - ETA: 231s - train loss: 6.0056shape (10, 24, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 277/1143 [======>.......................] - ETA: 231s - train loss: 6.0038shape (10, 24, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 278/1143 [======>.......................] - ETA: 231s - train loss: 5.9978shape (10, 23, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 279/1143 [======>.......................] - ETA: 230s - train loss: 5.9880shape (10, 42, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 280/1143 [======>.......................] - ETA: 230s - train loss: 5.9838shape (10, 47, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 281/1143 [======>.......................] - ETA: 231s - train loss: 5.9861shape (10, 58, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 282/1143 [======>.......................] - ETA: 231s - train loss: 6.0173shape (10, 33, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 283/1143 [======>.......................] - ETA: 231s - train loss: 6.0103shape (10, 17, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 284/1143 [======>.......................] - ETA: 231s - train loss: 6.0046shape (10, 30, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 285/1143 [======>.......................] - ETA: 230s - train loss: 5.9909shape (10, 28, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 286/1143 [======>.......................] - ETA: 230s - train loss: 5.9894shape (10, 39, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 287/1143 [======>.......................] - ETA: 230s - train loss: 5.9750shape (10, 20, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 288/1143 [======>.......................] - ETA: 230s - train loss: 5.9713shape (10, 14, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 289/1143 [======>.......................] - ETA: 229s - train loss: 5.9659shape (10, 47, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 290/1143 [======>.......................] - ETA: 229s - train loss: 5.9696shape (10, 22, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 291/1143 [======>.......................] - ETA: 229s - train loss: 5.9766shape (10, 33, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 292/1143 [======>.......................] - ETA: 229s - train loss: 5.9614shape (10, 48, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 293/1143 [======>.......................] - ETA: 229s - train loss: 5.9710shape (10, 30, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 294/1143 [======>.......................] - ETA: 229s - train loss: 5.9598shape (10, 13, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 295/1143 [======>.......................] - ETA: 228s - train loss: 5.9466shape (10, 57, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 296/1143 [======>.......................] - ETA: 229s - train loss: 5.9474shape (10, 28, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 297/1143 [======>.......................] - ETA: 228s - train loss: 5.9528shape (10, 10, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 298/1143 [======>.......................] - ETA: 228s - train loss: 5.9396shape (10, 32, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 299/1143 [======>.......................] - ETA: 228s - train loss: 5.9318shape (10, 14, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 300/1143 [======>.......................] - ETA: 227s - train loss: 5.9224shape (10, 18, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 301/1143 [======>.......................] - ETA: 227s - train loss: 5.9112shape (10, 24, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 302/1143 [======>.......................] - ETA: 226s - train loss: 5.9011shape (10, 29, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 303/1143 [======>.......................] - ETA: 226s - train loss: 5.9006shape (10, 29, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 304/1143 [======>.......................] - ETA: 226s - train loss: 5.9041shape (10, 26, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 305/1143 [=======>......................] - ETA: 226s - train loss: 5.9019shape (10, 19, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 306/1143 [=======>......................] - ETA: 225s - train loss: 5.8954shape (10, 30, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 307/1143 [=======>......................] - ETA: 225s - train loss: 5.8833shape (10, 16, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 308/1143 [=======>......................] - ETA: 224s - train loss: 5.8720shape (10, 26, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 309/1143 [=======>......................] - ETA: 224s - train loss: 5.8675shape (10, 17, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 310/1143 [=======>......................] - ETA: 224s - train loss: 5.8590shape (10, 22, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 311/1143 [=======>......................] - ETA: 223s - train loss: 5.8487shape (10, 14, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 312/1143 [=======>......................] - ETA: 223s - train loss: 5.8429shape (10, 21, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 313/1143 [=======>......................] - ETA: 222s - train loss: 5.8305shape (10, 34, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 314/1143 [=======>......................] - ETA: 222s - train loss: 5.8208shape (10, 48, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 315/1143 [=======>......................] - ETA: 222s - train loss: 5.8280shape (10, 17, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 316/1143 [=======>......................] - ETA: 222s - train loss: 5.8217shape (10, 18, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 317/1143 [=======>......................] - ETA: 221s - train loss: 5.8159shape (10, 20, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 318/1143 [=======>......................] - ETA: 221s - train loss: 5.8043shape (10, 25, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 319/1143 [=======>......................] - ETA: 221s - train loss: 5.7972shape (10, 65, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 320/1143 [=======>......................] - ETA: 221s - train loss: 5.7867shape (10, 32, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 321/1143 [=======>......................] - ETA: 221s - train loss: 5.7854shape (10, 15, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 322/1143 [=======>......................] - ETA: 220s - train loss: 5.7815shape (10, 39, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 323/1143 [=======>......................] - ETA: 220s - train loss: 5.7918shape (10, 23, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 324/1143 [=======>......................] - ETA: 220s - train loss: 5.7962shape (10, 37, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 325/1143 [=======>......................] - ETA: 220s - train loss: 5.8025shape (10, 25, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 326/1143 [=======>......................] - ETA: 219s - train loss: 5.7948shape (10, 29, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 327/1143 [=======>......................] - ETA: 219s - train loss: 5.7925shape (10, 33, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 328/1143 [=======>......................] - ETA: 219s - train loss: 5.7899shape (10, 19, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 329/1143 [=======>......................] - ETA: 218s - train loss: 5.7801shape (10, 31, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 330/1143 [=======>......................] - ETA: 218s - train loss: 5.7727shape (10, 16, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 331/1143 [=======>......................] - ETA: 218s - train loss: 5.7633shape (10, 37, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 332/1143 [=======>......................] - ETA: 218s - train loss: 5.7548shape (10, 15, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 333/1143 [=======>......................] - ETA: 217s - train loss: 5.7494shape (10, 43, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 334/1143 [=======>......................] - ETA: 217s - train loss: 5.7479shape (10, 51, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 335/1143 [=======>......................] - ETA: 217s - train loss: 5.7590shape (10, 23, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 336/1143 [=======>......................] - ETA: 217s - train loss: 5.7527shape (10, 26, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 337/1143 [=======>......................] - ETA: 216s - train loss: 5.7402shape (10, 12, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 338/1143 [=======>......................] - ETA: 216s - train loss: 5.7377shape (10, 25, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 339/1143 [=======>......................] - ETA: 216s - train loss: 5.7312shape (10, 24, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 340/1143 [=======>......................] - ETA: 215s - train loss: 5.7258shape (10, 47, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 341/1143 [=======>......................] - ETA: 215s - train loss: 5.7302shape (10, 23, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 342/1143 [=======>......................] - ETA: 215s - train loss: 5.7242shape (10, 19, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 343/1143 [========>.....................] - ETA: 215s - train loss: 5.7141shape (10, 39, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 344/1143 [========>.....................] - ETA: 214s - train loss: 5.7117shape (10, 23, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 345/1143 [========>.....................] - ETA: 214s - train loss: 5.7008shape (10, 26, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 346/1143 [========>.....................] - ETA: 214s - train loss: 5.6999shape (10, 8, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 347/1143 [========>.....................] - ETA: 213s - train loss: 5.6845shape (10, 25, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 348/1143 [========>.....................] - ETA: 213s - train loss: 5.6786shape (10, 34, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 349/1143 [========>.....................] - ETA: 213s - train loss: 5.6805shape (10, 41, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 350/1143 [========>.....................] - ETA: 213s - train loss: 5.6785shape (10, 33, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 351/1143 [========>.....................] - ETA: 212s - train loss: 5.6753shape (10, 23, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 352/1143 [========>.....................] - ETA: 212s - train loss: 5.6631shape (10, 24, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 353/1143 [========>.....................] - ETA: 212s - train loss: 5.6515shape (10, 25, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 354/1143 [========>.....................] - ETA: 211s - train loss: 5.6457shape (10, 43, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 355/1143 [========>.....................] - ETA: 211s - train loss: 5.6381shape (10, 35, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 356/1143 [========>.....................] - ETA: 211s - train loss: 5.6301shape (10, 20, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 357/1143 [========>.....................] - ETA: 211s - train loss: 5.6213shape (10, 16, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 358/1143 [========>.....................] - ETA: 210s - train loss: 5.6133shape (10, 30, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 359/1143 [========>.....................] - ETA: 210s - train loss: 5.6036shape (10, 39, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 360/1143 [========>.....................] - ETA: 210s - train loss: 5.6124shape (10, 28, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 361/1143 [========>.....................] - ETA: 210s - train loss: 5.6011shape (10, 28, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 362/1143 [========>.....................] - ETA: 209s - train loss: 5.6003shape (10, 16, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 363/1143 [========>.....................] - ETA: 209s - train loss: 5.5920shape (10, 17, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 364/1143 [========>.....................] - ETA: 208s - train loss: 5.5905shape (10, 17, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 365/1143 [========>.....................] - ETA: 208s - train loss: 5.5906shape (10, 20, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 366/1143 [========>.....................] - ETA: 208s - train loss: 5.5840shape (10, 33, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 367/1143 [========>.....................] - ETA: 207s - train loss: 5.5744shape (10, 38, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 368/1143 [========>.....................] - ETA: 207s - train loss: 5.5836shape (10, 19, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 369/1143 [========>.....................] - ETA: 207s - train loss: 5.5755shape (10, 20, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 370/1143 [========>.....................] - ETA: 207s - train loss: 5.5637shape (10, 16, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 371/1143 [========>.....................] - ETA: 206s - train loss: 5.5539shape (10, 10, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 372/1143 [========>.....................] - ETA: 206s - train loss: 5.5436shape (10, 117, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 373/1143 [========>.....................] - ETA: 207s - train loss: 5.5597shape (10, 12, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 374/1143 [========>.....................] - ETA: 206s - train loss: 5.5535shape (10, 33, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 375/1143 [========>.....................] - ETA: 206s - train loss: 5.5506shape (10, 25, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 376/1143 [========>.....................] - ETA: 206s - train loss: 5.5432shape (10, 11, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 377/1143 [========>.....................] - ETA: 205s - train loss: 5.5354shape (10, 34, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 378/1143 [========>.....................] - ETA: 205s - train loss: 5.5281shape (10, 44, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 379/1143 [========>.....................] - ETA: 205s - train loss: 5.5334shape (10, 47, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 380/1143 [========>.....................] - ETA: 205s - train loss: 5.5309shape (10, 18, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 381/1143 [=========>....................] - ETA: 205s - train loss: 5.5222shape (10, 40, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 382/1143 [=========>....................] - ETA: 205s - train loss: 5.5177shape (10, 20, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 383/1143 [=========>....................] - ETA: 204s - train loss: 5.5145shape (10, 33, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 384/1143 [=========>....................] - ETA: 204s - train loss: 5.5069shape (10, 23, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 385/1143 [=========>....................] - ETA: 204s - train loss: 5.4986shape (10, 13, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 386/1143 [=========>....................] - ETA: 203s - train loss: 5.4885shape (10, 26, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 387/1143 [=========>....................] - ETA: 203s - train loss: 5.4869shape (10, 41, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 388/1143 [=========>....................] - ETA: 203s - train loss: 5.4825shape (10, 62, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 389/1143 [=========>....................] - ETA: 203s - train loss: 5.4863shape (10, 27, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 390/1143 [=========>....................] - ETA: 203s - train loss: 5.4900shape (10, 33, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 391/1143 [=========>....................] - ETA: 203s - train loss: 5.4796shape (10, 14, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 392/1143 [=========>....................] - ETA: 202s - train loss: 5.4701shape (10, 29, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 393/1143 [=========>....................] - ETA: 202s - train loss: 5.4632shape (10, 98, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 394/1143 [=========>....................] - ETA: 203s - train loss: 5.4677shape (10, 15, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 395/1143 [=========>....................] - ETA: 202s - train loss: 5.4576shape (10, 53, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 396/1143 [=========>....................] - ETA: 202s - train loss: 5.4493shape (10, 29, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 397/1143 [=========>....................] - ETA: 202s - train loss: 5.4469shape (10, 28, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 398/1143 [=========>....................] - ETA: 202s - train loss: 5.4386shape (10, 7, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 399/1143 [=========>....................] - ETA: 201s - train loss: 5.4261shape (10, 15, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 400/1143 [=========>....................] - ETA: 201s - train loss: 5.4175shape (10, 36, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 401/1143 [=========>....................] - ETA: 201s - train loss: 5.4129shape (10, 25, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 402/1143 [=========>....................] - ETA: 201s - train loss: 5.4021shape (10, 15, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 403/1143 [=========>....................] - ETA: 200s - train loss: 5.3945shape (10, 25, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 404/1143 [=========>....................] - ETA: 200s - train loss: 5.3920shape (10, 27, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 405/1143 [=========>....................] - ETA: 200s - train loss: 5.3879shape (10, 22, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 406/1143 [=========>....................] - ETA: 199s - train loss: 5.3822shape (10, 116, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 407/1143 [=========>....................] - ETA: 200s - train loss: 5.3863shape (10, 20, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 408/1143 [=========>....................] - ETA: 200s - train loss: 5.3939shape (10, 23, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 409/1143 [=========>....................] - ETA: 200s - train loss: 5.3876shape (10, 34, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 410/1143 [=========>....................] - ETA: 199s - train loss: 5.3889shape (10, 20, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 411/1143 [=========>....................] - ETA: 199s - train loss: 5.3905shape (10, 18, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 412/1143 [=========>....................] - ETA: 199s - train loss: 5.3839shape (10, 32, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 413/1143 [=========>....................] - ETA: 198s - train loss: 5.3758shape (10, 35, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 414/1143 [=========>....................] - ETA: 198s - train loss: 5.3850shape (10, 23, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 415/1143 [=========>....................] - ETA: 198s - train loss: 5.3802shape (10, 59, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 416/1143 [=========>....................] - ETA: 198s - train loss: 5.3935shape (10, 29, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 417/1143 [=========>....................] - ETA: 198s - train loss: 5.3863shape (10, 16, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 418/1143 [=========>....................] - ETA: 197s - train loss: 5.3784shape (10, 17, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 419/1143 [=========>....................] - ETA: 197s - train loss: 5.3739shape (10, 22, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 420/1143 [==========>...................] - ETA: 197s - train loss: 5.3674shape (10, 26, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 421/1143 [==========>...................] - ETA: 196s - train loss: 5.3616shape (10, 18, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 422/1143 [==========>...................] - ETA: 196s - train loss: 5.3549shape (10, 35, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 423/1143 [==========>...................] - ETA: 196s - train loss: 5.3511shape (10, 22, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 424/1143 [==========>...................] - ETA: 195s - train loss: 5.3404shape (10, 23, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 425/1143 [==========>...................] - ETA: 195s - train loss: 5.3334shape (10, 11, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 426/1143 [==========>...................] - ETA: 194s - train loss: 5.3249shape (10, 21, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 427/1143 [==========>...................] - ETA: 194s - train loss: 5.3154shape (10, 19, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 428/1143 [==========>...................] - ETA: 194s - train loss: 5.3102shape (10, 30, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 429/1143 [==========>...................] - ETA: 193s - train loss: 5.3181shape (10, 32, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 430/1143 [==========>...................] - ETA: 193s - train loss: 5.3202shape (10, 31, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 431/1143 [==========>...................] - ETA: 193s - train loss: 5.3176shape (10, 25, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 432/1143 [==========>...................] - ETA: 193s - train loss: 5.3126shape (10, 19, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 433/1143 [==========>...................] - ETA: 192s - train loss: 5.3047shape (10, 30, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 434/1143 [==========>...................] - ETA: 192s - train loss: 5.3004shape (10, 31, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 435/1143 [==========>...................] - ETA: 192s - train loss: 5.3014shape (10, 24, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 436/1143 [==========>...................] - ETA: 192s - train loss: 5.2986shape (10, 18, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 437/1143 [==========>...................] - ETA: 191s - train loss: 5.2953shape (10, 23, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 438/1143 [==========>...................] - ETA: 191s - train loss: 5.2891shape (10, 33, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 439/1143 [==========>...................] - ETA: 191s - train loss: 5.2818shape (10, 27, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 440/1143 [==========>...................] - ETA: 191s - train loss: 5.2808shape (10, 23, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 441/1143 [==========>...................] - ETA: 190s - train loss: 5.2793shape (10, 26, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 442/1143 [==========>...................] - ETA: 190s - train loss: 5.2748shape (10, 14, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 443/1143 [==========>...................] - ETA: 190s - train loss: 5.2655shape (10, 28, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 444/1143 [==========>...................] - ETA: 189s - train loss: 5.2564shape (10, 37, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 445/1143 [==========>...................] - ETA: 189s - train loss: 5.2611shape (10, 23, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 446/1143 [==========>...................] - ETA: 189s - train loss: 5.2600shape (10, 16, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 447/1143 [==========>...................] - ETA: 188s - train loss: 5.2545shape (10, 31, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 448/1143 [==========>...................] - ETA: 188s - train loss: 5.2511shape (10, 26, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 449/1143 [==========>...................] - ETA: 188s - train loss: 5.2490shape (10, 24, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 450/1143 [==========>...................] - ETA: 187s - train loss: 5.2458shape (10, 36, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 451/1143 [==========>...................] - ETA: 187s - train loss: 5.2391shape (10, 36, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 452/1143 [==========>...................] - ETA: 187s - train loss: 5.2355shape (10, 29, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 453/1143 [==========>...................] - ETA: 187s - train loss: 5.2378shape (10, 19, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 454/1143 [==========>...................] - ETA: 186s - train loss: 5.2322shape (10, 17, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 455/1143 [==========>...................] - ETA: 186s - train loss: 5.2245shape (10, 15, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 456/1143 [==========>...................] - ETA: 186s - train loss: 5.2198shape (10, 17, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 457/1143 [==========>...................] - ETA: 185s - train loss: 5.2098shape (10, 28, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 458/1143 [===========>..................] - ETA: 185s - train loss: 5.2083shape (10, 25, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 459/1143 [===========>..................] - ETA: 185s - train loss: 5.2074shape (10, 14, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 460/1143 [===========>..................] - ETA: 184s - train loss: 5.2007shape (10, 26, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 461/1143 [===========>..................] - ETA: 184s - train loss: 5.1950shape (10, 20, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 462/1143 [===========>..................] - ETA: 184s - train loss: 5.1900shape (10, 15, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 463/1143 [===========>..................] - ETA: 183s - train loss: 5.1868shape (10, 18, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 464/1143 [===========>..................] - ETA: 183s - train loss: 5.1843shape (10, 12, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 465/1143 [===========>..................] - ETA: 182s - train loss: 5.1753shape (10, 28, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 466/1143 [===========>..................] - ETA: 182s - train loss: 5.1729shape (10, 29, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 467/1143 [===========>..................] - ETA: 182s - train loss: 5.1650shape (10, 17, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 468/1143 [===========>..................] - ETA: 182s - train loss: 5.1576shape (10, 32, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 469/1143 [===========>..................] - ETA: 181s - train loss: 5.1488shape (10, 17, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 470/1143 [===========>..................] - ETA: 181s - train loss: 5.1391shape (10, 32, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 471/1143 [===========>..................] - ETA: 181s - train loss: 5.1416shape (10, 13, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 472/1143 [===========>..................] - ETA: 180s - train loss: 5.1350shape (10, 12, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 473/1143 [===========>..................] - ETA: 180s - train loss: 5.1277shape (10, 28, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 474/1143 [===========>..................] - ETA: 180s - train loss: 5.1235shape (10, 14, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 475/1143 [===========>..................] - ETA: 179s - train loss: 5.1197shape (10, 15, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 476/1143 [===========>..................] - ETA: 179s - train loss: 5.1141shape (10, 11, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 477/1143 [===========>..................] - ETA: 178s - train loss: 5.1062shape (10, 10, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 478/1143 [===========>..................] - ETA: 178s - train loss: 5.0995shape (10, 32, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 479/1143 [===========>..................] - ETA: 178s - train loss: 5.0989shape (10, 36, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 480/1143 [===========>..................] - ETA: 177s - train loss: 5.0968shape (10, 32, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 481/1143 [===========>..................] - ETA: 177s - train loss: 5.0937shape (10, 33, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 482/1143 [===========>..................] - ETA: 177s - train loss: 5.1051shape (10, 20, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 483/1143 [===========>..................] - ETA: 177s - train loss: 5.1010shape (10, 48, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 484/1143 [===========>..................] - ETA: 177s - train loss: 5.1055shape (10, 25, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 485/1143 [===========>..................] - ETA: 176s - train loss: 5.1032shape (10, 44, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 486/1143 [===========>..................] - ETA: 176s - train loss: 5.1083shape (10, 27, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 487/1143 [===========>..................] - ETA: 176s - train loss: 5.1073shape (10, 22, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 488/1143 [===========>..................] - ETA: 176s - train loss: 5.1118shape (10, 24, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 489/1143 [===========>..................] - ETA: 175s - train loss: 5.1075shape (10, 18, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 490/1143 [===========>..................] - ETA: 175s - train loss: 5.0998shape (10, 27, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 491/1143 [===========>..................] - ETA: 175s - train loss: 5.1004shape (10, 6, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 492/1143 [===========>..................] - ETA: 174s - train loss: 5.0915shape (10, 36, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 493/1143 [===========>..................] - ETA: 174s - train loss: 5.0851shape (10, 21, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 494/1143 [===========>..................] - ETA: 174s - train loss: 5.0819shape (10, 29, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 495/1143 [===========>..................] - ETA: 173s - train loss: 5.0770shape (10, 25, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 496/1143 [============>.................] - ETA: 173s - train loss: 5.0741shape (10, 18, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 497/1143 [============>.................] - ETA: 173s - train loss: 5.0694shape (10, 25, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 498/1143 [============>.................] - ETA: 172s - train loss: 5.0660shape (10, 22, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 499/1143 [============>.................] - ETA: 172s - train loss: 5.0594shape (10, 17, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 500/1143 [============>.................] - ETA: 172s - train loss: 5.0553shape (10, 17, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 501/1143 [============>.................] - ETA: 171s - train loss: 5.0470shape (10, 27, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 502/1143 [============>.................] - ETA: 171s - train loss: 5.0416shape (10, 20, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 503/1143 [============>.................] - ETA: 171s - train loss: 5.0374shape (10, 17, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 504/1143 [============>.................] - ETA: 170s - train loss: 5.0355shape (10, 26, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 505/1143 [============>.................] - ETA: 170s - train loss: 5.0342shape (10, 28, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 506/1143 [============>.................] - ETA: 170s - train loss: 5.0294shape (10, 15, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 507/1143 [============>.................] - ETA: 170s - train loss: 5.0234shape (10, 39, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 508/1143 [============>.................] - ETA: 169s - train loss: 5.0208shape (10, 20, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 509/1143 [============>.................] - ETA: 169s - train loss: 5.0184shape (10, 39, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 510/1143 [============>.................] - ETA: 169s - train loss: 5.0171shape (10, 18, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 511/1143 [============>.................] - ETA: 169s - train loss: 5.0137shape (10, 82, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 512/1143 [============>.................] - ETA: 169s - train loss: 5.0096shape (10, 25, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 513/1143 [============>.................] - ETA: 169s - train loss: 5.0031shape (10, 60, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 514/1143 [============>.................] - ETA: 169s - train loss: 5.0062shape (10, 35, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 515/1143 [============>.................] - ETA: 168s - train loss: 5.0010shape (10, 37, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 516/1143 [============>.................] - ETA: 168s - train loss: 4.9978shape (10, 10, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 517/1143 [============>.................] - ETA: 168s - train loss: 4.9978shape (10, 25, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 518/1143 [============>.................] - ETA: 167s - train loss: 5.0022shape (10, 14, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 519/1143 [============>.................] - ETA: 167s - train loss: 4.9979shape (10, 50, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 520/1143 [============>.................] - ETA: 167s - train loss: 5.0013shape (10, 26, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 521/1143 [============>.................] - ETA: 167s - train loss: 4.9980shape (10, 23, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 522/1143 [============>.................] - ETA: 167s - train loss: 4.9987shape (10, 28, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 523/1143 [============>.................] - ETA: 166s - train loss: 4.9998shape (10, 13, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 524/1143 [============>.................] - ETA: 166s - train loss: 4.9918shape (10, 47, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 525/1143 [============>.................] - ETA: 166s - train loss: 4.9906shape (10, 42, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 526/1143 [============>.................] - ETA: 166s - train loss: 4.9891shape (10, 24, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 527/1143 [============>.................] - ETA: 165s - train loss: 4.9841shape (10, 35, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 528/1143 [============>.................] - ETA: 165s - train loss: 4.9854shape (10, 28, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 529/1143 [============>.................] - ETA: 165s - train loss: 4.9820shape (10, 22, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 530/1143 [============>.................] - ETA: 164s - train loss: 4.9778shape (10, 9, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 531/1143 [============>.................] - ETA: 164s - train loss: 4.9689shape (10, 34, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 532/1143 [============>.................] - ETA: 164s - train loss: 4.9672shape (10, 40, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 533/1143 [============>.................] - ETA: 164s - train loss: 4.9657shape (10, 25, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 534/1143 [=============>................] - ETA: 163s - train loss: 4.9604shape (10, 41, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 535/1143 [=============>................] - ETA: 163s - train loss: 4.9708shape (10, 25, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 536/1143 [=============>................] - ETA: 163s - train loss: 4.9669shape (10, 14, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 537/1143 [=============>................] - ETA: 162s - train loss: 4.9600shape (10, 24, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 538/1143 [=============>................] - ETA: 162s - train loss: 4.9557shape (10, 28, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 539/1143 [=============>................] - ETA: 162s - train loss: 4.9496shape (10, 35, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 540/1143 [=============>................] - ETA: 162s - train loss: 4.9496shape (10, 36, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 541/1143 [=============>................] - ETA: 162s - train loss: 4.9629shape (10, 35, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 542/1143 [=============>................] - ETA: 161s - train loss: 4.9640shape (10, 27, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 543/1143 [=============>................] - ETA: 161s - train loss: 4.9560shape (10, 24, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 544/1143 [=============>................] - ETA: 161s - train loss: 4.9487shape (10, 13, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 545/1143 [=============>................] - ETA: 160s - train loss: 4.9491shape (10, 26, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 546/1143 [=============>................] - ETA: 160s - train loss: 4.9503shape (10, 21, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 547/1143 [=============>................] - ETA: 160s - train loss: 4.9449shape (10, 22, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 548/1143 [=============>................] - ETA: 159s - train loss: 4.9420shape (10, 16, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 549/1143 [=============>................] - ETA: 159s - train loss: 4.9363shape (10, 23, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 550/1143 [=============>................] - ETA: 159s - train loss: 4.9362shape (10, 24, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 551/1143 [=============>................] - ETA: 158s - train loss: 4.9311shape (10, 15, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 552/1143 [=============>................] - ETA: 158s - train loss: 4.9254shape (10, 21, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 553/1143 [=============>................] - ETA: 158s - train loss: 4.9195shape (10, 19, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 554/1143 [=============>................] - ETA: 157s - train loss: 4.9146shape (10, 10, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 555/1143 [=============>................] - ETA: 157s - train loss: 4.9091shape (10, 22, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 556/1143 [=============>................] - ETA: 157s - train loss: 4.9080shape (10, 18, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 557/1143 [=============>................] - ETA: 156s - train loss: 4.9043shape (10, 32, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 558/1143 [=============>................] - ETA: 156s - train loss: 4.9104shape (10, 14, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 559/1143 [=============>................] - ETA: 156s - train loss: 4.9044shape (10, 25, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 560/1143 [=============>................] - ETA: 155s - train loss: 4.8997shape (10, 26, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 561/1143 [=============>................] - ETA: 155s - train loss: 4.8930shape (10, 19, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 562/1143 [=============>................] - ETA: 155s - train loss: 4.8942shape (10, 8, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 563/1143 [=============>................] - ETA: 154s - train loss: 4.8865shape (10, 52, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 564/1143 [=============>................] - ETA: 154s - train loss: 4.8853shape (10, 38, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 565/1143 [=============>................] - ETA: 154s - train loss: 4.8856shape (10, 28, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 566/1143 [=============>................] - ETA: 154s - train loss: 4.8806shape (10, 16, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 567/1143 [=============>................] - ETA: 154s - train loss: 4.8758shape (10, 25, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 568/1143 [=============>................] - ETA: 153s - train loss: 4.8716shape (10, 18, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 569/1143 [=============>................] - ETA: 153s - train loss: 4.8689shape (10, 41, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 570/1143 [=============>................] - ETA: 153s - train loss: 4.8656shape (10, 38, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 571/1143 [=============>................] - ETA: 153s - train loss: 4.8644shape (10, 17, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 572/1143 [==============>...............] - ETA: 152s - train loss: 4.8631shape (10, 18, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 573/1143 [==============>...............] - ETA: 152s - train loss: 4.8566shape (10, 28, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 574/1143 [==============>...............] - ETA: 152s - train loss: 4.8519shape (10, 31, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 575/1143 [==============>...............] - ETA: 152s - train loss: 4.8469shape (10, 20, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 576/1143 [==============>...............] - ETA: 151s - train loss: 4.8450shape (10, 15, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 577/1143 [==============>...............] - ETA: 151s - train loss: 4.8402shape (10, 27, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 578/1143 [==============>...............] - ETA: 151s - train loss: 4.8401shape (10, 7, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 579/1143 [==============>...............] - ETA: 150s - train loss: 4.8326shape (10, 28, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 580/1143 [==============>...............] - ETA: 150s - train loss: 4.8385shape (10, 26, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 581/1143 [==============>...............] - ETA: 150s - train loss: 4.8391shape (10, 53, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 582/1143 [==============>...............] - ETA: 149s - train loss: 4.8371shape (10, 30, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 583/1143 [==============>...............] - ETA: 149s - train loss: 4.8309shape (10, 17, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 584/1143 [==============>...............] - ETA: 149s - train loss: 4.8283shape (10, 23, 3072)\n",
      "hahaha, I got it!!!!!!!!!\n",
      " 585/1143 [==============>...............] - ETA: 149s - train loss: 4.8218"
     ]
    }
   ],
   "source": [
    "# import pdb; pdb.seet_trace()\n",
    "\n",
    "from config import Config\n",
    "from model.data_utils import CoNLLDataset\n",
    "from model.ner_model import NERModel\n",
    "import ray\n",
    "import ray.tune as tune\n",
    "import tensorflow as tf\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "config = Config()\n",
    "\n",
    "tf.reset_default_graph()\n",
    "# build model\n",
    "model = NERModel(config)\n",
    "model.build()\n",
    "# model.restore_session(\"results/crf/model.weights/\") # optional, restore weights\n",
    "#model.reinitialize_weights(\"proj\")\n",
    "\n",
    "\n",
    "# create datasets\n",
    "\n",
    "# elmo = 1\n",
    "dev   = CoNLLDataset(config.filename_dev, config.processing_word,\n",
    "                     config.processing_tag, config.max_iter)\n",
    "train = CoNLLDataset(config.filename_train, config.processing_word,\n",
    "                     config.processing_tag, config.max_iter)\n",
    "\n",
    "# train model\n",
    "model.train(train, dev, elmo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv-allen",
   "language": "python",
   "name": "pyenv-allen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
